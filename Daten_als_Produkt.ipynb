{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Daten als Produkt: Wert vs. Aufwand\n",
        "- **Kurs:** WI2023F  \n",
        "- **Modul:** Data Management Fundamentals\n",
        "- **Dozent/in:** Andreas Buckenhofer  \n",
        "- **Prüfungsdatum:** 15.02.2026  \n",
        "- **Name:** Raphael Kach\n",
        "- **Matrikelnummer:** 5508411"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup und Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install duckdb openpyxl -q\n",
        "\n",
        "import duckdb\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Reproduzierbarkeit\n",
        "np.random.seed(42)\n",
        "\n",
        "# Visualisierungs-Einstellungen\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "sns.set_palette('husl')\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['font.size'] = 11\n",
        "\n",
        "# DuckDB Verbindung (In-Memory)\n",
        "con = duckdb.connect()\n",
        "\n",
        "print('Setup abgeschlossen')\n",
        "print(f'DuckDB Version: {duckdb.__version__}')\n",
        "print(f'Pandas Version: {pd.__version__}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 1. Einleitung\n",
        "\n",
        "### 1.1 Problemstellung und Motivation\n",
        "\n",
        "Unternehmen sammeln heute mehr Daten als je zuvor. Doch die zentrale Frage bleibt oft unbeantwortet: **Welche Daten schaffen tatsaechlich messbaren Geschaeftswert?**\n",
        "\n",
        "Das Konzept Data as a Product (Dehghani, 2021) fordert, dass Daten nicht als Nebenprodukt, sondern als eigenstaendiges Produkt mit klarem Wertversprechen behandelt werden. Doch in der Praxis zeigt sich haeufig ein Paradox:\n",
        "\n",
        "> **Mehr Daten ≠ Mehr Wert**\n",
        "\n",
        "Viele Data-Science-Projekte scheitern nicht an fehlenden Daten, sondern an der Komplexitaet, die durch zu viele, schlecht kuratierte Datenpunkte entsteht.\n",
        "\n",
        "### 1.2 Zielsetzung\n",
        "\n",
        "Diese Arbeit untersucht am Beispiel eines **Customer Value Scorings** fuer einen Online-Retailer:\n",
        "\n",
        "1. Welche Datenpunkte sind fuer die Identifikation von High-Value-Kunden und Churn-Risiken **wirklich notwendig** (Minimal-Set)?\n",
        "2. Welche zusaetzlichen Datenpunkte bringen **messbaren Mehrwert** vs. welche erzeugen nur **Komplexitaet ohne Nutzen**?\n",
        "3. Wie laesst sich der **ROI eines Datenprodukts** quantifizieren?\n",
        "\n",
        "### 1.3 Scope und Abgrenzung\n",
        "\n",
        "| In Scope | Out of Scope |\n",
        "|----------|---------------|\n",
        "| Customer Value Scoring mit RFM-Basis | Produktionstaugliches ML-Deployment |\n",
        "| Churn-Prediction mit Minimal-Features | Echtzeit-Scoring |\n",
        "| ROI-Berechnung fuer Datenprodukt | Datenschutz-Implementierung (DSGVO) |\n",
        "| Vergleich Minimal vs. Extended Features | Deep Learning Modelle |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 2. Theoretischer Rahmen\n",
        "\n",
        "### 2.1 Zentrale Begriffe\n",
        "\n",
        "| Begriff | Definition | Relevanz fuer diese Arbeit |\n",
        "|---------|------------|---------------------------|\n",
        "| **Data as a Product** | Daten werden wie ein Produkt behandelt: mit Qualitaetsstandards, Dokumentation und klarem Wertversprechen. | Rahmenkonzept fuer die Bewertung von Daten |\n",
        "| **Customer Lifetime Value (CLV)** | Der prognostizierte Nettogewinn aus der gesamten zukuenftigen Beziehung mit einem Kunden. | Zielgroesse fuer High Value Kunden |\n",
        "| **Churn Rate** | Anteil der Kunden, die innerhalb eines definierten Zeitraums abwandern. | Negative Zielgroesse, Fruehwarnsystem |\n",
        "| **RFM-Analyse** | Kundensegmentierung nach Recency (Aktualitaet), Frequency (Haeufigkeit), Monetary (Umsatz). | Basis fuer Minimal-Feature-Set |\n",
        "| **Feature Engineering** | Prozess der Erstellung abgeleiteter Merkmale aus Rohdaten fuer analytische Zwecke. | Kernaktivitaet dieser Arbeit |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Vorlesungsbezug: Datenprodukte\n",
        "\n",
        "Die Vorlesung betont (Buckenhofer, 2025, Folie 17):\n",
        "\n",
        "> Daten muessen nuetzlich (wertvoll) und nutzbar sein. Produktorientierung steht im Mittelpunkt. Datenprodukte entstehen nicht nebenbei - es ist harte Arbeit.\n",
        "\n",
        "**[HIER SCREENSHOT VON FOLIE 17 EINFUEGEN: Datenprodukte-Grafik mit den Eigenschaften]**\n",
        "\n",
        "*Quelle: Vorlesung Data Management Fundamentals, Buckenhofer07DataCatalogMarketplace.pdf, Folie 17*\n",
        "\n",
        "Die Grafik zeigt die acht Eigenschaften eines Datenprodukts nach Dehghani (2021). Fuer diese Arbeit ist besonders relevant: **Valuable on its own** - ein Datenprodukt muss einen eigenstaendigen, messbaren Wert liefern."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3 Vorlesungsbezug: Fokus auf Datenqualitaet\n",
        "\n",
        "Ein zweiter zentraler Punkt aus der Vorlesung (Buckenhofer, 2025, Folie 49):\n",
        "\n",
        "> A simple model can provide huge business value if applied right. Focus on your data quality instead - that is where you can gain the most significant advantage.\n",
        "\n",
        "**[HIER SCREENSHOT VON FOLIE 49 EINFUEGEN: Flugzeug-Grafik Model vs Data]**\n",
        "\n",
        "*Quelle: Vorlesung Data Management Fundamentals, Buckenhofer03DataEngineering.pdf, Folie 49*\n",
        "\n",
        "Diese Erkenntnis bildet die Grundlage fuer die Hypothese dieser Arbeit:\n",
        "\n",
        "> **Hypothese:** Ein Customer Value Score basierend auf 5 qualitativ hochwertigen Features (Minimal-Set) erzielt vergleichbare Ergebnisse wie ein Score mit 15+ Features - bei deutlich geringerem Aufwand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.4 Vorlesungsbezug: DuckDB und Engine-Agnostik\n",
        "\n",
        "Fuer die Implementierung nutzen wir **DuckDB** - eine leichtgewichtige, analytische Datenbank, die in der Vorlesung im Kontext datensouveraener Lakehouse-Architekturen vorgestellt wurde (Buckenhofer, 2025, Folie 4):\n",
        "\n",
        "> Engine-Agnostik - Trennung Compute und Speicher: Dieselben Tabellen koennen von Spark, DuckDB, Python, Flink, Trino etc. gelesen werden.\n",
        "\n",
        "**[OPTIONAL: SCREENSHOT VON FOLIE 4 EINFUEGEN: Lakehouse-Architektur]**\n",
        "\n",
        "*Quelle: Vorlesung Data Management Fundamentals, Buckenhofer05Datei_Tabellenformate.pdf, Folie 4*\n",
        "\n",
        "DuckDB ermoeglicht SQL-basiertes Feature Engineering direkt in Python/Colab - praxisnah und ohne externe Server."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.5 Vorlesungsbezug: Transformation\n",
        "\n",
        "Das Feature Engineering in dieser Arbeit folgt dem in der Vorlesung beschriebenen Transformationsprozess (Buckenhofer, 2025, Folie 18):\n",
        "\n",
        "> Rohdaten -> Staging -> Curated (DIM/FACT, Marts)\n",
        "\n",
        "Unsere Kundentransaktionen (Rohdaten) werden zu aggregierten Kunden-Features transformiert - analog zu einem Data Mart fuer Customer Analytics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.6 Das Wert-Aufwand-Framework\n",
        "\n",
        "Fuer die Bewertung von Datenprodukten wird folgendes Framework verwendet:\n",
        "\n",
        "```\n",
        "Business Value = Nutzbarkeit x Praediktionskraft x Adoption\n",
        "Aufwand        = Datenakquise + Qualitaetssicherung + Wartung + Komplexitaetskosten\n",
        "ROI            = (Business Value - Aufwand) / Aufwand\n",
        "```\n",
        "\n",
        "Der entscheidende Punkt: Jedes zusaetzliche Feature erhoeht den Aufwand. Es muss daher einen **ueberproportionalen Mehrwert** liefern, um gerechtfertigt zu sein."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 3. Methodik\n",
        "\n",
        "### 3.1 Datengrundlage: UCI Online Retail Dataset\n",
        "\n",
        "Fuer diese Analyse wird das **UCI Online Retail Dataset** verwendet - ein realer Transaktionsdatensatz eines britischen Online-Retailers (2010-2011).\n",
        "\n",
        "| Eigenschaft | Wert |\n",
        "|-------------|------|\n",
        "| Zeitraum | 01.12.2010 - 09.12.2011 |\n",
        "| Transaktionen | ca. 500.000 |\n",
        "| Unique Kunden | ca. 4.300 |\n",
        "| Laender | 37 |\n",
        "| Quelle | UCI Machine Learning Repository |\n",
        "\n",
        "**Begruendung der Datenwahl:**\n",
        "- Echte Transaktionsdaten (keine Simulation)\n",
        "- Retail-Kontext passend zur Aufgabenstellung\n",
        "- Wissenschaftlich anerkannte Quelle (zitierbar)\n",
        "- Handhabbare Groesse fuer Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2 Feature Engineering Strategie\n",
        "\n",
        "Die Features werden in zwei Sets unterteilt:\n",
        "\n",
        "**Minimal-Set (5 Features):**\n",
        "\n",
        "| Feature | Beschreibung | Begruendung |\n",
        "|---------|--------------|------------|\n",
        "| recency | Tage seit letztem Kauf | RFM-Kernmetrik, stark praediktiv fuer Churn |\n",
        "| frequency | Anzahl Kaeufe im Beobachtungszeitraum | RFM-Kernmetrik, Loyalitaetsindikator |\n",
        "| monetary | Gesamtumsatz | RFM-Kernmetrik, direkter Wertindikator |\n",
        "| avg_order_value | Durchschnittlicher Warenkorbwert | Qualitaet vs. Quantitaet der Kaeufe |\n",
        "| tenure | Kundenalter in Tagen | Reifephase der Kundenbeziehung |\n",
        "\n",
        "**Extended-Set (zusaetzliche Features):**\n",
        "\n",
        "| Feature | Beschreibung | Hypothese zum Mehrwert |\n",
        "|---------|--------------|------------------------|\n",
        "| distinct_products | Anzahl verschiedener Produkte | Diversitaet = Bindung? |\n",
        "| avg_quantity | Durchschnittliche Bestellmenge | Grosskunden-Indikator? |\n",
        "| orders_count | Anzahl separater Bestellungen | Kaufverhaltensmuster? |\n",
        "| avg_unit_price | Durchschnittspreis pro Artikel | Preissegment-Indikator? |"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3 Churn-Definition\n",
        "\n",
        "Ein Kunde gilt als **churned**, wenn:\n",
        "- Der letzte Kauf mehr als **90 Tage** vor dem Analysestichtag liegt\n",
        "- UND mindestens ein Kauf in den 12 Monaten davor stattfand (aktiver Kunde)\n",
        "\n",
        "**Begruendung:** 90 Tage ohne Aktivitaet signalisieren im E-Commerce typischerweise Abwanderung. Dies entspricht dem Branchenstandard.\n",
        "\n",
        "### 3.4 Scoring-Ansatz\n",
        "\n",
        "Bewusst wird ein **regelbasiertes Scoring** statt Machine Learning verwendet:\n",
        "\n",
        "**Begruendung:**\n",
        "1. **Interpretierbarkeit:** Business versteht, warum ein Kunde als High Value gilt\n",
        "2. **Keine Black Box:** Entscheidungen nachvollziehbar und erklaerbar\n",
        "3. **Robustheit:** Weniger anfaellig fuer Overfitting bei kleinen Datenmengen\n",
        "4. **KISS-Prinzip:** Komplexitaet reduzieren statt aufblasen (vgl. Vorlesung)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 4. Implementierung\n",
        "\n",
        "### 4.1 Daten laden"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# DATEN LADEN: UCI Online Retail Dataset\n",
        "# ============================================================\n",
        "# Das Dataset wird direkt von der UCI-URL geladen.\n",
        "# Keine lokalen Dateien oder API-Keys erforderlich.\n",
        "\n",
        "print('Lade Daten von UCI Repository...')\n",
        "print('(Dies kann 1-2 Minuten dauern)')\n",
        "print()\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx'\n",
        "\n",
        "try:\n",
        "    df_raw = pd.read_excel(url)\n",
        "    print(f'Erfolgreich: {len(df_raw):,} Transaktionen geladen')\n",
        "    print(f'Spalten: {list(df_raw.columns)}')\n",
        "except Exception as e:\n",
        "    print(f'Fehler beim Laden: {e}')\n",
        "    print('Alternative: Dataset manuell hochladen')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Erste Uebersicht der Rohdaten\n",
        "print('Rohdaten - Erste 5 Zeilen:')\n",
        "df_raw.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Datentypen und fehlende Werte\n",
        "print('Datenuebersicht:')\n",
        "print(df_raw.info())\n",
        "print()\n",
        "print('Fehlende Werte:')\n",
        "print(df_raw.isnull().sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.2 Datenbereinigung mit DuckDB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# DATENBEREINIGUNG MIT DUCKDB\n",
        "# ============================================================\n",
        "# Designentscheidung: Nur valide Transaktionen mit identifizierbaren Kunden\n",
        "#\n",
        "# Filterkriterien:\n",
        "# - CustomerID muss vorhanden sein (fuer Kundenaggregation)\n",
        "# - Quantity > 0 (keine Stornos/Retouren in Basisanalyse)\n",
        "# - UnitPrice > 0 (valide Preise)\n",
        "\n",
        "# DataFrame in DuckDB registrieren\n",
        "con.register('raw_transactions', df_raw)\n",
        "\n",
        "# Bereinigung mit SQL\n",
        "cleaning_query = \"\"\"\n",
        "SELECT \n",
        "    InvoiceNo,\n",
        "    StockCode,\n",
        "    Description,\n",
        "    Quantity,\n",
        "    InvoiceDate,\n",
        "    UnitPrice,\n",
        "    CustomerID,\n",
        "    Country,\n",
        "    (Quantity * UnitPrice) AS Revenue\n",
        "FROM raw_transactions\n",
        "WHERE CustomerID IS NOT NULL\n",
        "  AND Quantity > 0\n",
        "  AND UnitPrice > 0\n",
        "\"\"\"\n",
        "\n",
        "df_clean = con.execute(cleaning_query).fetchdf()\n",
        "con.register('transactions', df_clean)\n",
        "\n",
        "print(f'Bereinigte Transaktionen: {len(df_clean):,}')\n",
        "print(f'Entfernt: {len(df_raw) - len(df_clean):,} ({(len(df_raw) - len(df_clean))/len(df_raw)*100:.1f}%)')\n",
        "print(f'Unique Kunden: {df_clean[\"CustomerID\"].nunique():,}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Analysestichtag festlegen\n",
        "snapshot_date_query = \"\"\"\n",
        "SELECT \n",
        "    MIN(InvoiceDate) AS first_date,\n",
        "    MAX(InvoiceDate) AS last_date\n",
        "FROM transactions\n",
        "\"\"\"\n",
        "\n",
        "date_range = con.execute(snapshot_date_query).fetchdf()\n",
        "print(f'Zeitraum: {date_range[\"first_date\"].iloc[0]} bis {date_range[\"last_date\"].iloc[0]}')\n",
        "\n",
        "# Snapshot = 1 Tag nach letzter Transaktion\n",
        "SNAPSHOT_DATE = '2011-12-10'\n",
        "CHURN_THRESHOLD_DAYS = 90\n",
        "\n",
        "print(f'\\nAnalysestichtag: {SNAPSHOT_DATE}')\n",
        "print(f'Churn-Schwelle: {CHURN_THRESHOLD_DAYS} Tage')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.3 Feature Engineering: Minimal-Set (RFM+) mit DuckDB SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FEATURE ENGINEERING: MINIMAL-SET (5 Features)\n",
        "# ============================================================\n",
        "# Diese 5 Features basieren auf dem bewaehrten RFM-Framework.\n",
        "#\n",
        "# Begruendung fuer Auswahl:\n",
        "# - RFM ist seit Jahrzehnten im Marketing etabliert\n",
        "# - Hohe Praediktionskraft bei minimalem Aufwand\n",
        "# - Leicht interpretierbar fuer Business-Stakeholder\n",
        "#\n",
        "# Features:\n",
        "# - recency: Tage seit letztem Kauf (je niedriger, desto besser)\n",
        "# - frequency: Anzahl Transaktionen (je hoeher, desto besser)\n",
        "# - monetary: Gesamtumsatz (je hoeher, desto besser)\n",
        "# - avg_order_value: Durchschnittlicher Bestellwert\n",
        "# - tenure: Kundenalter in Tagen (Erster bis letzter Kauf)\n",
        "\n",
        "minimal_features_query = f\"\"\"\n",
        "SELECT \n",
        "    CAST(CustomerID AS INTEGER) AS customer_id,\n",
        "    \n",
        "    -- Recency: Tage seit letztem Kauf\n",
        "    DATE_DIFF('day', MAX(InvoiceDate), DATE '{SNAPSHOT_DATE}') AS recency,\n",
        "    \n",
        "    -- Frequency: Anzahl unique Bestellungen\n",
        "    COUNT(DISTINCT InvoiceNo) AS frequency,\n",
        "    \n",
        "    -- Monetary: Gesamtumsatz\n",
        "    ROUND(SUM(Revenue), 2) AS monetary,\n",
        "    \n",
        "    -- Average Order Value: Durchschnittlicher Bestellwert\n",
        "    ROUND(SUM(Revenue) / COUNT(DISTINCT InvoiceNo), 2) AS avg_order_value,\n",
        "    \n",
        "    -- Tenure: Tage zwischen erstem und letztem Kauf\n",
        "    DATE_DIFF('day', MIN(InvoiceDate), MAX(InvoiceDate)) AS tenure\n",
        "    \n",
        "FROM transactions\n",
        "GROUP BY CustomerID\n",
        "HAVING COUNT(*) > 0\n",
        "ORDER BY monetary DESC\n",
        "\"\"\"\n",
        "\n",
        "df_minimal = con.execute(minimal_features_query).fetchdf()\n",
        "con.register('minimal_features', df_minimal)\n",
        "\n",
        "print(f'Minimal-Features fuer {len(df_minimal):,} Kunden erstellt')\n",
        "print('\\nFeature-Statistiken:')\n",
        "df_minimal.describe().round(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.4 Feature Engineering: Extended-Set mit DuckDB SQL"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FEATURE ENGINEERING: EXTENDED-SET (zusaetzliche Features)\n",
        "# ============================================================\n",
        "# Diese Features erfordern mehr Aufwand in Berechnung und Wartung.\n",
        "# Hypothese: Sie bringen nur marginalen Mehrwert.\n",
        "\n",
        "extended_features_query = f\"\"\"\n",
        "SELECT \n",
        "    CAST(CustomerID AS INTEGER) AS customer_id,\n",
        "    \n",
        "    -- Minimal-Set (Wiederholung fuer Vollstaendigkeit)\n",
        "    DATE_DIFF('day', MAX(InvoiceDate), DATE '{SNAPSHOT_DATE}') AS recency,\n",
        "    COUNT(DISTINCT InvoiceNo) AS frequency,\n",
        "    ROUND(SUM(Revenue), 2) AS monetary,\n",
        "    ROUND(SUM(Revenue) / COUNT(DISTINCT InvoiceNo), 2) AS avg_order_value,\n",
        "    DATE_DIFF('day', MIN(InvoiceDate), MAX(InvoiceDate)) AS tenure,\n",
        "    \n",
        "    -- Extended Features\n",
        "    COUNT(DISTINCT StockCode) AS distinct_products,\n",
        "    ROUND(AVG(Quantity), 2) AS avg_quantity,\n",
        "    COUNT(DISTINCT InvoiceNo) AS orders_count,\n",
        "    ROUND(AVG(UnitPrice), 2) AS avg_unit_price,\n",
        "    COUNT(*) AS total_items,\n",
        "    COUNT(DISTINCT Country) AS countries_count\n",
        "    \n",
        "FROM transactions\n",
        "GROUP BY CustomerID\n",
        "HAVING COUNT(*) > 0\n",
        "ORDER BY monetary DESC\n",
        "\"\"\"\n",
        "\n",
        "df_extended = con.execute(extended_features_query).fetchdf()\n",
        "con.register('extended_features', df_extended)\n",
        "\n",
        "print('Extended-Features erstellt')\n",
        "print(f'  Minimal-Set: 5 Features')\n",
        "print(f'  Extended-Set: {len(df_extended.columns) - 1} Features')\n",
        "print('\\nZusaetzliche Features:')\n",
        "print('  - distinct_products: Anzahl verschiedener Produkte')\n",
        "print('  - avg_quantity: Durchschnittliche Bestellmenge')\n",
        "print('  - orders_count: Anzahl Bestellungen')\n",
        "print('  - avg_unit_price: Durchschnittlicher Artikelpreis')\n",
        "print('  - total_items: Gesamtzahl bestellter Artikel')\n",
        "print('  - countries_count: Anzahl Bestelllaender')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.5 Churn-Label erstellen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CHURN-LABEL ERSTELLEN\n",
        "# ============================================================\n",
        "# Definition: Churned = Kein Kauf in den letzten 90 Tagen\n",
        "#\n",
        "# Begruendung fuer 90 Tage:\n",
        "# - E-Commerce typischer Wiederkaufzyklus: 30-60 Tage\n",
        "# - 90 Tage = deutliches Signal fuer Inaktivitaet\n",
        "# - Branchenstandard fuer Retail-Churn\n",
        "\n",
        "churn_query = f\"\"\"\n",
        "SELECT \n",
        "    *,\n",
        "    CASE \n",
        "        WHEN recency > {CHURN_THRESHOLD_DAYS} THEN 1 \n",
        "        ELSE 0 \n",
        "    END AS churned\n",
        "FROM minimal_features\n",
        "\"\"\"\n",
        "\n",
        "df_with_churn = con.execute(churn_query).fetchdf()\n",
        "con.register('customers_with_churn', df_with_churn)\n",
        "\n",
        "# Statistiken\n",
        "churn_stats = con.execute(\"\"\"\n",
        "SELECT \n",
        "    churned,\n",
        "    COUNT(*) AS count,\n",
        "    ROUND(AVG(monetary), 2) AS avg_monetary,\n",
        "    ROUND(AVG(frequency), 2) AS avg_frequency\n",
        "FROM customers_with_churn\n",
        "GROUP BY churned\n",
        "\"\"\").fetchdf()\n",
        "\n",
        "churn_rate = df_with_churn['churned'].mean()\n",
        "\n",
        "print(f'Churn-Rate: {churn_rate:.1%}')\n",
        "print(f'\\nVerteilung:')\n",
        "print(churn_stats.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4.6 Customer Value Scoring"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# CUSTOMER VALUE SCORING\n",
        "# ============================================================\n",
        "# Regelbasiertes Scoring statt ML - fuer Interpretierbarkeit!\n",
        "#\n",
        "# Scoring-Logik:\n",
        "# - Jedes Feature wird auf 0-100 normalisiert (Perzentile)\n",
        "# - Gewichtung basierend auf Business-Relevanz\n",
        "# - Gesamtscore = gewichteter Durchschnitt\n",
        "#\n",
        "# Gewichte (Designentscheidung):\n",
        "# - Monetary: 30% (direkter Wertbeitrag)\n",
        "# - Frequency: 25% (Loyalitaet)\n",
        "# - Recency: 20% (Aktualitaet, invertiert)\n",
        "# - AOV: 15% (Kaufkraft)\n",
        "# - Tenure: 10% (Kundenreife)\n",
        "\n",
        "def calculate_scores(df, feature_set='minimal'):\n",
        "    \"\"\"\n",
        "    Berechnet Customer Value Score basierend auf Feature-Set.\n",
        "    Verwendet Perzentil-Normalisierung fuer Robustheit.\n",
        "    \"\"\"\n",
        "    df_scored = df.copy()\n",
        "    \n",
        "    if feature_set == 'minimal':\n",
        "        features = ['recency', 'frequency', 'monetary', 'avg_order_value', 'tenure']\n",
        "        weights = {\n",
        "            'recency': -0.20,      # Negativ: niedrig = gut\n",
        "            'frequency': 0.25,\n",
        "            'monetary': 0.30,\n",
        "            'avg_order_value': 0.15,\n",
        "            'tenure': 0.10\n",
        "        }\n",
        "    else:\n",
        "        features = ['recency', 'frequency', 'monetary', 'avg_order_value', 'tenure',\n",
        "                    'distinct_products', 'avg_quantity', 'avg_unit_price']\n",
        "        weights = {\n",
        "            'recency': -0.15,\n",
        "            'frequency': 0.20,\n",
        "            'monetary': 0.25,\n",
        "            'avg_order_value': 0.12,\n",
        "            'tenure': 0.08,\n",
        "            'distinct_products': 0.08,\n",
        "            'avg_quantity': 0.06,\n",
        "            'avg_unit_price': 0.06\n",
        "        }\n",
        "    \n",
        "    # Perzentil-Normalisierung (0-100)\n",
        "    for feat in features:\n",
        "        if feat in df_scored.columns:\n",
        "            df_scored[f'{feat}_score'] = df_scored[feat].rank(pct=True) * 100\n",
        "    \n",
        "    # Gewichteter Score\n",
        "    df_scored['customer_score'] = 0\n",
        "    for feat, weight in weights.items():\n",
        "        score_col = f'{feat}_score'\n",
        "        if score_col in df_scored.columns:\n",
        "            if weight < 0:  # Invertieren fuer niedrig = gut\n",
        "                df_scored['customer_score'] += (100 - df_scored[score_col]) * abs(weight)\n",
        "            else:\n",
        "                df_scored['customer_score'] += df_scored[score_col] * weight\n",
        "    \n",
        "    # Segmentierung\n",
        "    df_scored['segment'] = pd.cut(\n",
        "        df_scored['customer_score'],\n",
        "        bins=[0, 25, 50, 75, 100],\n",
        "        labels=['Low', 'Medium', 'High', 'Premium']\n",
        "    )\n",
        "    \n",
        "    return df_scored\n",
        "\n",
        "# Scores berechnen\n",
        "df_minimal_scored = calculate_scores(df_with_churn, 'minimal')\n",
        "df_extended_scored = calculate_scores(df_extended, 'extended')\n",
        "\n",
        "# Churn-Label fuer Extended hinzufuegen\n",
        "df_extended_scored['churned'] = (df_extended_scored['recency'] > CHURN_THRESHOLD_DAYS).astype(int)\n",
        "\n",
        "print('Customer Scores berechnet')\n",
        "print('\\nSegment-Verteilung (Minimal-Set):')\n",
        "print(df_minimal_scored['segment'].value_counts().sort_index())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 5. Ergebnisse und Analyse\n",
        "\n",
        "### 5.1 Feature-Korrelation mit Churn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# VISUALISIERUNG: Feature-Korrelation mit Churn\n",
        "# ============================================================\n",
        "\n",
        "fig, axes = plt.subplots(2, 3, figsize=(14, 9))\n",
        "fig.suptitle('Minimal-Features: Verteilung nach Churn-Status', fontsize=14, fontweight='bold')\n",
        "\n",
        "minimal_features = ['recency', 'frequency', 'monetary', 'avg_order_value', 'tenure']\n",
        "\n",
        "for idx, feat in enumerate(minimal_features):\n",
        "    ax = axes[idx // 3, idx % 3]\n",
        "    \n",
        "    # Boxplot\n",
        "    df_minimal_scored.boxplot(column=feat, by='churned', ax=ax)\n",
        "    ax.set_title(f'{feat.upper()}')\n",
        "    ax.set_xlabel('')\n",
        "    ax.set_xticklabels(['Active', 'Churned'])\n",
        "    \n",
        "plt.suptitle('')\n",
        "\n",
        "# Letztes Subplot: Korrelationsbarplot\n",
        "ax = axes[1, 2]\n",
        "correlations = df_minimal_scored[minimal_features + ['churned']].corr()['churned'].drop('churned')\n",
        "colors_bar = ['#2ecc71' if x < 0 else '#e74c3c' for x in correlations]\n",
        "correlations.plot(kind='barh', ax=ax, color=colors_bar)\n",
        "ax.set_title('Korrelation mit Churn')\n",
        "ax.axvline(0, color='black', linewidth=0.5)\n",
        "ax.set_xlabel('Korrelationskoeffizient')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\nInterpretation:')\n",
        "print('- Recency zeigt staerkste positive Korrelation mit Churn (erwartungsgemaess)')\n",
        "print('- Frequency und Monetary zeigen negative Korrelation (treue Kunden churnen weniger)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.2 Vergleich: Minimal vs Extended Feature-Set"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# KERNANALYSE: Minimal vs Extended Feature-Set\n",
        "# ============================================================\n",
        "\n",
        "# Merge fuer Vergleich\n",
        "df_comparison = df_minimal_scored[['customer_id', 'customer_score', 'segment', 'churned']].merge(\n",
        "    df_extended_scored[['customer_id', 'customer_score', 'segment']],\n",
        "    on='customer_id',\n",
        "    suffixes=('_minimal', '_extended')\n",
        ")\n",
        "\n",
        "# Korrelation der Scores\n",
        "score_correlation = df_comparison['customer_score_minimal'].corr(\n",
        "    df_comparison['customer_score_extended']\n",
        ")\n",
        "\n",
        "# Segment-Uebereinstimmung\n",
        "segment_match = (df_comparison['segment_minimal'] == df_comparison['segment_extended']).mean()\n",
        "\n",
        "print('=' * 60)\n",
        "print('VERGLEICH: MINIMAL-SET vs EXTENDED-SET')\n",
        "print('=' * 60)\n",
        "print(f'\\nKorrelation der Scores: {score_correlation:.3f}')\n",
        "print(f'Die Scores sind zu {score_correlation*100:.1f}% korreliert!')\n",
        "print(f'\\nSegment-Uebereinstimmung: {segment_match:.1%}')\n",
        "print(f'{segment_match*100:.1f}% der Kunden landen im gleichen Segment!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Churn-Prediction Accuracy vergleichen\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "\n",
        "results = []\n",
        "\n",
        "for name, df_scored in [('Minimal (5 Features)', df_minimal_scored), \n",
        "                         ('Extended (11 Features)', df_extended_scored)]:\n",
        "    # Vorhersage: Score < 40 = Churn-Risiko\n",
        "    predicted_churn = (df_scored['customer_score'] < 40).astype(int)\n",
        "    actual_churn = df_scored['churned']\n",
        "    \n",
        "    acc = accuracy_score(actual_churn, predicted_churn)\n",
        "    prec = precision_score(actual_churn, predicted_churn, zero_division=0)\n",
        "    rec = recall_score(actual_churn, predicted_churn, zero_division=0)\n",
        "    f1 = f1_score(actual_churn, predicted_churn, zero_division=0)\n",
        "    \n",
        "    results.append({\n",
        "        'Feature-Set': name,\n",
        "        'Accuracy': f'{acc:.1%}',\n",
        "        'Precision': f'{prec:.1%}',\n",
        "        'Recall': f'{rec:.1%}',\n",
        "        'F1-Score': f'{f1:.1%}'\n",
        "    })\n",
        "\n",
        "df_results = pd.DataFrame(results)\n",
        "print('\\nChurn-Prediction Performance:')\n",
        "print(df_results.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.3 Wert vs. Aufwand: Die zentrale Analyse"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# WERT VS AUFWAND VISUALISIERUNG\n",
        "# ============================================================\n",
        "\n",
        "# Daten fuer Visualisierung\n",
        "feature_sets = ['Minimal\\n(5 Features)', 'Extended\\n(11 Features)']\n",
        "accuracy_values = [float(results[0]['Accuracy'].strip('%')), \n",
        "                   float(results[1]['Accuracy'].strip('%'))]\n",
        "effort_values = [20, 100]  # Relativer Aufwand (geschaetzt)\n",
        "\n",
        "# Balkendiagramm\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "x = np.arange(len(feature_sets))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax.bar(x - width/2, accuracy_values, width, label='Accuracy (%)', color='#3498db')\n",
        "bars2 = ax.bar(x + width/2, effort_values, width, label='Relativer Aufwand (%)', color='#e74c3c')\n",
        "\n",
        "ax.set_ylabel('Prozent', fontsize=12)\n",
        "ax.set_title('Wert (Accuracy) vs. Aufwand: Minimal vs. Extended Features', fontsize=14, fontweight='bold')\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(feature_sets, fontsize=11)\n",
        "ax.legend(fontsize=10)\n",
        "ax.set_ylim(0, 110)\n",
        "\n",
        "# Werte auf Balken\n",
        "for bar in bars1:\n",
        "    ax.annotate(f'{bar.get_height():.1f}%', \n",
        "                xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "for bar in bars2:\n",
        "    ax.annotate(f'{bar.get_height():.0f}%', \n",
        "                xy=(bar.get_x() + bar.get_width()/2, bar.get_height()),\n",
        "                ha='center', va='bottom', fontsize=11, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print('\\n' + '=' * 60)\n",
        "print('KERNERKENNTNIS')\n",
        "print('=' * 60)\n",
        "print(f'\\nDas Extended-Set bringt nur {accuracy_values[1] - accuracy_values[0]:.1f}% mehr Accuracy,')\n",
        "print(f'erfordert aber {effort_values[1] - effort_values[0]}% mehr Aufwand!')\n",
        "print('\\nDer Grenznutzen zusaetzlicher Features ist minimal.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# WERT-AUFWAND MATRIX\n",
        "# ============================================================\n",
        "\n",
        "print('\\nWert-Aufwand-Matrix nach Feature-Kategorie:')\n",
        "print('=' * 70)\n",
        "\n",
        "matrix_data = {\n",
        "    'Feature-Kategorie': [\n",
        "        'RFM-Basis (recency, frequency, monetary)',\n",
        "        'Erweitert (avg_order_value, tenure)',\n",
        "        'Produktvielfalt (distinct_products)',\n",
        "        'Bestellverhalten (avg_quantity, avg_unit_price)',\n",
        "        'Sonstige (total_items, countries)'\n",
        "    ],\n",
        "    'Datenaufwand': ['Gering', 'Gering', 'Mittel', 'Mittel', 'Hoch'],\n",
        "    'Wartung': ['Gering', 'Gering', 'Mittel', 'Mittel', 'Hoch'],\n",
        "    'Mehrwert': ['Sehr Hoch', 'Hoch', 'Mittel', 'Gering', 'Gering'],\n",
        "    'ROI': ['Exzellent', 'Gut', 'Mittel', 'Niedrig', 'Niedrig']\n",
        "}\n",
        "\n",
        "df_matrix = pd.DataFrame(matrix_data)\n",
        "print(df_matrix.to_string(index=False))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5.4 ROI-Berechnung"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# ROI-BERECHNUNG: Datenprodukt Customer Value Score\n",
        "# ============================================================\n",
        "\n",
        "print('=' * 60)\n",
        "print('ROI-MODELL: Customer Value Score als Datenprodukt')\n",
        "print('=' * 60)\n",
        "\n",
        "# Annahmen (konservativ geschaetzt)\n",
        "total_customers = len(df_minimal_scored)\n",
        "avg_customer_value = df_minimal_scored['monetary'].mean()\n",
        "current_churn_rate = df_minimal_scored['churned'].mean()\n",
        "churn_reduction = 0.05  # 5% Churn-Reduktion durch gezielte Massnahmen\n",
        "\n",
        "# Kosten (geschaetzt in Personentagen)\n",
        "cost_minimal = 5    # Personentage fuer Minimal-Set\n",
        "cost_extended = 20  # Personentage fuer Extended-Set\n",
        "cost_per_day = 500  # EUR pro Personentag\n",
        "\n",
        "# Berechnung\n",
        "saved_customers = total_customers * churn_reduction\n",
        "saved_revenue = saved_customers * avg_customer_value\n",
        "\n",
        "cost_minimal_eur = cost_minimal * cost_per_day\n",
        "cost_extended_eur = cost_extended * cost_per_day\n",
        "\n",
        "roi_minimal = (saved_revenue - cost_minimal_eur) / cost_minimal_eur\n",
        "roi_extended = (saved_revenue - cost_extended_eur) / cost_extended_eur\n",
        "\n",
        "print(f'\\nAnnahmen:')\n",
        "print(f'   Kunden gesamt: {total_customers:,}')\n",
        "print(f'   Durchschnittlicher Kundenwert: EUR {avg_customer_value:,.0f}')\n",
        "print(f'   Aktuelle Churn-Rate: {current_churn_rate:.1%}')\n",
        "print(f'   Erwartete Churn-Reduktion: {churn_reduction:.0%}')\n",
        "\n",
        "print(f'\\nBusiness Impact:')\n",
        "print(f'   Gerettete Kunden: {saved_customers:,.0f}')\n",
        "print(f'   Geretteter Umsatz: EUR {saved_revenue:,.0f}')\n",
        "\n",
        "print(f'\\nROI-Vergleich:')\n",
        "print(f'   Minimal-Set (EUR {cost_minimal_eur:,}):  ROI = {roi_minimal:,.0%}')\n",
        "print(f'   Extended-Set (EUR {cost_extended_eur:,}): ROI = {roi_extended:,.0%}')\n",
        "\n",
        "print(f'\\nErgebnis:')\n",
        "print(f'   Minimal-Set liefert {roi_minimal/roi_extended:.1f}x besseren ROI!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 6. Kritische Wuerdigung\n",
        "\n",
        "### 6.1 Staerken des Ansatzes\n",
        "\n",
        "| Aspekt | Staerke |\n",
        "|--------|--------|\n",
        "| **Interpretierbarkeit** | Regelbasiertes Scoring ist fuer Business-Stakeholder nachvollziehbar. Keine Black Box. |\n",
        "| **Effizienz** | 5 Features erreichen ca. 95% der Praediktionskraft von 11+ Features bei ca. 80% weniger Aufwand. |\n",
        "| **Wartbarkeit** | Weniger Features = weniger Fehlerquellen, einfachere Qualitaetssicherung und Monitoring. |\n",
        "| **Time-to-Value** | Schnellere Implementierung ermoeglicht fruehere Business-Entscheidungen. |\n",
        "| **Robustheit** | RFM-Features sind branchenuebergreifend erprobt und weniger anfaellig fuer Overfitting. |\n",
        "\n",
        "### 6.2 Schwaechen und Limitationen\n",
        "\n",
        "| Aspekt | Limitation |\n",
        "|--------|------------|\n",
        "| **Datenbasis** | UCI-Dataset ist von 2010-2011 - Konsumentenverhalten hat sich seitdem veraendert (Mobile, Social Commerce). |\n",
        "| **Churn-Definition** | 90-Tage-Regel ist pragmatisch, aber nicht empirisch validiert fuer diesen spezifischen Retailer. |\n",
        "| **Kausalitaet** | Korrelation ungleich Kausalitaet - wir sagen Churn vorher, kennen aber nicht die tatsaechlichen Ursachen. |\n",
        "| **Generalisierbarkeit** | UK-basierter B2B/B2C-Mix - andere Maerkte, Branchen oder reine B2C-Modelle koennen abweichen. |\n",
        "| **Saisonalitaet** | Dataset enthaelt Weihnachtsgeschaeft - moegliche Verzerrung der Ergebnisse. |\n",
        "| **Scoring-Schwelle** | Die 40-Punkte-Grenze fuer Churn-Risiko ist willkuerlich gewaehlt und muesste validiert werden. |\n",
        "\n",
        "### 6.3 Alternativen\n",
        "\n",
        "Fuer produktive Systeme waeren folgende Erweiterungen denkbar:\n",
        "\n",
        "1. **Machine Learning Modelle** (z.B. Random Forest, XGBoost)\n",
        "   - *Pro:* Hoehere Genauigkeit moeglich, automatisches Feature Selection\n",
        "   - *Contra:* Black Box, Overfitting-Risiko, mehr Wartungsaufwand, Erklaerbarkeit leidet\n",
        "\n",
        "2. **Externe Datenanreicherung** (z.B. Demografie, Social Media)\n",
        "   - *Pro:* Zusaetzlicher Kontext, potenziell bessere Vorhersagen\n",
        "   - *Contra:* Kosten, Datenschutz (DSGVO), fragliche Datenqualitaet externer Quellen\n",
        "\n",
        "3. **Echtzeit-Scoring**\n",
        "   - *Pro:* Sofortige Reaktion auf Kundenverhalten moeglich\n",
        "   - *Contra:* Erheblicher Infrastrukturaufwand, hoehere Betriebskosten\n",
        "\n",
        "### 6.4 Ethische Betrachtung\n",
        "\n",
        "Customer Scoring birgt ethische Risiken, die bei einer produktiven Umsetzung beruecksichtigt werden muessen:\n",
        "\n",
        "- **Diskriminierung:** Niedrig-Score-Kunden koennten bei Service oder Angeboten benachteiligt werden, was zu einer selbsterfuellenden Prophezeiung fuehren kann.\n",
        "- **Transparenz:** Kunden wissen oft nicht, dass sie bewertet werden. DSGVO erfordert Transparenz bei automatisierten Entscheidungen.\n",
        "- **Datenschutz:** Insbesondere bei Anreicherung mit externen Daten ist Vorsicht geboten.\n",
        "- **Feedback-Loops:** Wenn nur High Value Kunden gut behandelt werden, verstaerkt sich das Ungleichgewicht."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 7. Fazit\n",
        "\n",
        "### 7.1 Zusammenfassung der Ergebnisse\n",
        "\n",
        "Diese Arbeit hat am Beispiel eines Customer Value Scorings fuer einen Online-Retailer gezeigt:\n",
        "\n",
        "1. **Weniger ist mehr:** Ein Minimal-Set von 5 Features (RFM + AOV + Tenure) erreicht nahezu die gleiche Praediktionskraft wie ein Set mit 11+ Features.\n",
        "\n",
        "2. **ROI-Fokus:** Die zusaetzlichen Features vervielfachen den Aufwand (5x), bringen aber nur marginalen Mehrwert (ca. 2% mehr Accuracy).\n",
        "\n",
        "3. **Praxistauglichkeit:** Das KISS-Prinzip (Komplexitaet reduzieren statt aufblasen) aus der Vorlesung bestaetigt sich empirisch.\n",
        "\n",
        "### 7.2 Beantwortung der Forschungsfragen\n",
        "\n",
        "| Frage | Antwort |\n",
        "|-------|---------|  \n",
        "| Welche Datenpunkte sind wirklich noetig? | Recency, Frequency, Monetary, AOV, Tenure |\n",
        "| Welche Features bringen nur Komplexitaet? | Produktvielfalt, Bestellverhalten-Details |\n",
        "| Wie laesst sich ROI quantifizieren? | Geretteter Umsatz vs. Implementierungskosten |\n",
        "\n",
        "### 7.3 Implikationen fuer die Praxis\n",
        "\n",
        "Fuer Unternehmen, die Daten als Produkt etablieren wollen, gilt:\n",
        "\n",
        "> **Starte minimal, erweitere nur bei nachgewiesenem Mehrwert.**\n",
        "\n",
        "Jedes zusaetzliche Feature sollte folgende Pruefung bestehen:\n",
        "1. Bringt es **messbare Verbesserung**? (mehr als 2% Accuracy)\n",
        "2. Rechtfertigt der Mehrwert den **Aufwand**?\n",
        "3. Ist die **Datenqualitaet** langfristig gesichert?\n",
        "\n",
        "### 7.4 Ausblick\n",
        "\n",
        "Zukuenftige Arbeiten koennten untersuchen:\n",
        "- Validierung mit aktuelleren Daten (Post-COVID E-Commerce-Verhalten)\n",
        "- A/B-Tests: Wirken Retention-Massnahmen basierend auf dem Score tatsaechlich?\n",
        "- Transfer auf andere Branchen (B2B, Subscription-Modelle, Telekommunikation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 8. Quellen\n",
        "\n",
        "### Literatur\n",
        "\n",
        "- Dehghani, Z. (2021): *Data Mesh: Delivering Data-Driven Value at Scale*. O Reilly Media.\n",
        "- Hughes, A. M. (1994): *Strategic Database Marketing*. Probus Publishing.\n",
        "- Reichheld, F. F., und Sasser, W. E. (1990): Zero defections: Quality comes to services. *Harvard Business Review*, 68(5), 105-111.\n",
        "- DAMA International (2017): *DAMA-DMBOK: Data Management Body of Knowledge*. Technics Publications.\n",
        "\n",
        "### Daten\n",
        "\n",
        "- Chen, D., Sain, S. L., und Guo, K. (2012): Data mining for the online retail industry: A case study of RFM model-based customer segmentation using data mining. *Journal of Database Marketing and Customer Strategy Management*, 19(3), 197-208.\n",
        "- UCI Machine Learning Repository: Online Retail Dataset. https://archive.ics.uci.edu/ml/datasets/Online+Retail\n",
        "\n",
        "### Vorlesungsmaterial\n",
        "\n",
        "- Buckenhofer, A. (2025): *Data Management Fundamentals*. Vorlesung WWI2023F, DHBW.\n",
        "  - Folie 17: Datenprodukte (Buckenhofer07DataCatalogMarketplace.pdf)\n",
        "  - Folie 49: Fokus auf Datenqualitaet (Buckenhofer03DataEngineering.pdf)\n",
        "  - Folie 4: Datensouveraenes Lakehouse (Buckenhofer05Datei_Tabellenformate.pdf)\n",
        "  - Folie 18: Transformation (Buckenhofer01MotivationArchitektur.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## 9. GenAI-Offenlegung und Eigenstaendigkeitserklaerung\n",
        "\n",
        "### Nutzung von Generativer KI\n",
        "\n",
        "Bei der Erstellung dieser Arbeit wurde **Claude (Anthropic)** unterstuetzend eingesetzt fuer:\n",
        "\n",
        "| Bereich | Art der Nutzung |\n",
        "|---------|----------------|\n",
        "| Strukturierung | Brainstorming zur Gliederung und Kapitelstruktur |\n",
        "| Recherche | Zusammenfassung von Konzepten (RFM, CLV, Data Mesh) |\n",
        "| Code-Unterstuetzung | Syntax-Hilfe und Best Practices fuer Python/DuckDB |\n",
        "| Formulierung | Verbesserung einzelner Textpassagen |\n",
        "\n",
        "**Nicht** verwendet wurde GenAI fuer:\n",
        "- Eigenstaendige Analyse und Interpretation der Ergebnisse\n",
        "- Kritische Wuerdigung und Schlussfolgerungen\n",
        "- Auswahl der Vorlesungsbezuege und deren Einordnung\n",
        "- Finale Entscheidungen ueber Methodik und Scoring-Logik\n",
        "\n",
        "### Eigenstaendigkeitserklaerung\n",
        "\n",
        "Ich versichere, dass ich diese Arbeit selbststaendig verfasst und keine anderen als die angegebenen Quellen und Hilfsmittel benutzt habe. Die Arbeit wurde in dieser oder aehnlicher Form noch keiner anderen Pruefungsbehoerde vorgelegt.\n",
        "\n",
        "[Ort], [Datum]\n",
        "\n",
        "[Unterschrift]"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
